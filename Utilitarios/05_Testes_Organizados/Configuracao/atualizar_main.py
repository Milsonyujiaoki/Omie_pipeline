#!/usr/bin/env python3
"""
Atualizador do Main.py para Nova Estrutura
==========================================

Este script atualiza o main.py principal para usar a nova estrutura
de c√≥digo organizada seguindo Clean Architecture.

FUNCIONALIDADES:
‚úÖ Atualiza imports para nova estrutura
‚úÖ Implementa dependency injection b√°sico
‚úÖ Aplica padr√£o Service Locator
‚úÖ Mant√©m compatibilidade com configura√ß√µes existentes
‚úÖ Cria vers√£o de backup antes das altera√ß√µes
"""

import shutil
from pathlib import Path
from datetime import datetime
import logging

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class AtualizadorMain:
    """Atualizador do arquivo main.py para nova estrutura."""
    
    def __init__(self):
        self.main_file = Path("main.py")
        self.backup_file = Path(f"main_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}.py")
        self.novo_main_content = self._gerar_novo_main()
    
    def executar_atualizacao(self) -> None:
        """Executa a atualiza√ß√£o do main.py."""
        try:
            logger.info("ATUALIZANDO MAIN.PY PARA NOVA ESTRUTURA")
            logger.info("=" * 50)
            
            # 1. Criar backup
            self._criar_backup()
            
            # 2. Atualizar main.py
            self._atualizar_main()
            
            # 3. Relat√≥rio
            self._gerar_relatorio()
            
            logger.info("‚úÖ MAIN.PY ATUALIZADO COM SUCESSO!")
            
        except Exception as e:
            logger.exception(f"‚ùå Erro durante atualiza√ß√£o: {e}")
            raise
    
    def _criar_backup(self) -> None:
        """Cria backup do main.py atual."""
        logger.info(f"üíæ Criando backup: {self.backup_file}")
        shutil.copy2(self.main_file, self.backup_file)
        logger.info("‚úì Backup criado")
    
    def _atualizar_main(self) -> None:
        """Atualiza o conte√∫do do main.py."""
        logger.info("üìù Atualizando main.py...")
        
        with open(self.main_file, 'w', encoding='utf-8') as f:
            f.write(self.novo_main_content)
        
        logger.info("‚úì main.py atualizado")
    
    def _gerar_relatorio(self) -> None:
        """Gera relat√≥rio da atualiza√ß√£o."""
        relatorio = f"""
üìã RELAT√ìRIO DE ATUALIZA√á√ÉO DO MAIN.PY
======================================

‚úÖ ATUALIZA√á√ïES REALIZADAS:
‚Ä¢ Imports atualizados para nova estrutura
‚Ä¢ Implementado padr√£o Service Locator
‚Ä¢ Adicionado dependency injection b√°sico
‚Ä¢ Mantida compatibilidade com configura√ß√µes
‚Ä¢ Estrutura preparada para testes unit√°rios

üíæ BACKUP CRIADO: {self.backup_file}
üèóÔ∏è NOVO MAIN.PY: Estrutura Clean Architecture

üöÄ BENEF√çCIOS:
‚Ä¢ C√≥digo mais modular e test√°vel
‚Ä¢ Separa√ß√£o clara de responsabilidades  
‚Ä¢ Facilita manuten√ß√£o e evolu√ß√£o
‚Ä¢ Preparado para crescimento do projeto

‚úÖ ATUALIZA√á√ÉO CONCLU√çDA!
"""
        
        logger.info(relatorio)
    
    def _gerar_novo_main(self) -> str:
        """Gera o novo conte√∫do do main.py."""
        return '''# =============================================================================
# PIPELINE PRINCIPAL DO EXTRATOR OMIE V3 - ESTRUTURA REFATORADA
# =============================================================================
"""
Pipeline principal refatorado seguindo Clean Architecture.

Este m√≥dulo orquestra todo o pipeline usando a nova estrutura modular:
- Core: Entidades e regras de neg√≥cio
- Application: Casos de uso e servi√ßos
- Adapters: Infraestrutura e APIs externas
- Infrastructure: Configura√ß√µes e logging

Benef√≠cios da nova estrutura:
‚úÖ Separa√ß√£o clara de responsabilidades
‚úÖ C√≥digo mais test√°vel e maint√≠vel
‚úÖ Baixo acoplamento entre m√≥dulos
‚úÖ Facilita evolu√ß√£o e escalabilidade
"""

# =============================================================================
# Importa√ß√µes da biblioteca padr√£o
# =============================================================================
import sys
import os
import time
import logging
import sqlite3
import configparser
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional, Protocol
from contextlib import contextmanager

# =============================================================================
# Importa√ß√µes da nova estrutura - Clean Architecture
# =============================================================================

# Infrastructure Layer
from src_novo.infrastructure.config.atualizar_query_params_ini import atualizar_datas_configuracao_ini
from src_novo.infrastructure.logging.setup import configurar_logging

# Application Layer - Services
from src_novo.application.services.extrator_async import baixar_xmls, listar_nfs
from src_novo.application.services.verificador_xmls import verificar as verificar_xmls
from src_novo.application.services.compactador_resultado import compactar_resultados
from src_novo.application.services.atualizar_caminhos_arquivos import atualizar_caminhos_no_banco
from src_novo.application.services.report_arquivos_vazios import gerar_relatorio as gerar_relatorio_vazios

# Adapters Layer - External APIs
from src_novo.adapters.external_apis.omie.omie_client_async import OmieClient, carregar_configuracoes as carregar_config_omie
from src_novo.adapters.external_apis.onedrive.upload_onedrive import fazer_upload_lote

# Utils Layer
from src_novo.utils.utils import (
    iniciar_db, 
    atualizar_anomesdia,
    atualizar_campos_registros_pendentes,
    formatar_tempo_total
)

# =============================================================================
# Configura√ß√µes globais
# =============================================================================
CONFIG_PATH: str = "configuracao.ini"

# =============================================================================
# Service Locator Pattern - Dependency Injection Simples
# =============================================================================

class ServiceLocator:
    """
    Service Locator para gerenciar depend√™ncias de forma centralizada.
    
    Implementa um padr√£o simples de dependency injection que facilita
    testes unit√°rios e manuten√ß√£o do c√≥digo.
    """
    
    def __init__(self):
        self._services: Dict[str, Any] = {}
        self._configuracoes: Optional[Dict[str, Any]] = None
    
    def registrar_servico(self, nome: str, servico: Any) -> None:
        """Registra um servi√ßo no locator."""
        self._services[nome] = servico
        logger.debug(f"[SERVICE_LOCATOR] Servi√ßo registrado: {nome}")
    
    def obter_servico(self, nome: str) -> Any:
        """Obt√©m um servi√ßo registrado."""
        if nome not in self._services:
            raise ValueError(f"Servi√ßo n√£o registrado: {nome}")
        return self._services[nome]
    
    def configurar_servicos(self, config: Dict[str, Any]) -> None:
        """Configura todos os servi√ßos com as configura√ß√µes."""
        self._configuracoes = config
        
        # Registra cliente Omie
        omie_client = OmieClient(
            app_key=config['app_key'],
            app_secret=config['app_secret'],
            calls_per_second=config.get('calls_per_second', 4)
        )
        self.registrar_servico('omie_client', omie_client)
        
        # Registra configura√ß√µes
        self.registrar_servico('config', config)
        
        logger.info("[SERVICE_LOCATOR] Servi√ßos configurados com sucesso")
    
    def obter_configuracoes(self) -> Dict[str, Any]:
        """Obt√©m configura√ß√µes carregadas."""
        if self._configuracoes is None:
            raise ValueError("Configura√ß√µes n√£o foram carregadas")
        return self._configuracoes

# Inst√¢ncia global do service locator
service_locator = ServiceLocator()

# =============================================================================
# Configura√ß√£o de logging - Infrastructure Layer
# =============================================================================

def configurar_sistema_logging() -> None:
    """Configura sistema de logging usando infrastructure layer."""
    try:
        # Tenta usar o configurador da nova estrutura
        configurar_logging()
        logger.info("[LOGGING] Sistema configurado via infrastructure layer")
    except ImportError:
        # Fallback para configura√ß√£o b√°sica
        _configurar_logging_basico()
        logger.warning("[LOGGING] Usando configura√ß√£o b√°sica (fallback)")

def _configurar_logging_basico() -> None:
    """Configura√ß√£o b√°sica de logging como fallback."""
    log_dir = Path("log")
    log_dir.mkdir(exist_ok=True)
    
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    log_file = log_dir / f"Pipeline_Refatorado_{timestamp}.log"
    
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s - %(levelname)s - %(message)s",
        handlers=[
            logging.FileHandler(log_file, encoding='utf-8'),
            logging.StreamHandler(sys.stdout)
        ],
        force=True
    )

# Configura√ß√£o inicial
_configurar_logging_basico()
logger = logging.getLogger(__name__)

# =============================================================================
# Gerenciamento de configura√ß√µes - Infrastructure Layer
# =============================================================================

def carregar_configuracoes(config_path: str = CONFIG_PATH) -> Dict[str, Any]:
    """
    Carrega configura√ß√µes usando infrastructure layer.
    
    Args:
        config_path: Caminho para arquivo de configura√ß√£o
        
    Returns:
        Dict com configura√ß√µes carregadas
        
    Raises:
        SystemExit: Se configura√ß√µes inv√°lidas
    """
    try:
        # Tenta usar carregador da nova estrutura
        config = carregar_config_omie()
        
        # Valida√ß√µes b√°sicas
        required_keys = ['app_key', 'app_secret', 'resultado_dir']
        for key in required_keys:
            if key not in config:
                logger.error(f"[CONFIG] Chave obrigat√≥ria ausente: {key}")
                sys.exit(1)
        
        logger.info("[CONFIG] Configura√ß√µes carregadas via adapters layer")
        return config
        
    except ImportError:
        # Fallback para carregamento b√°sico
        return _carregar_configuracoes_basico(config_path)

def _carregar_configuracoes_basico(config_path: str) -> Dict[str, Any]:
    """Carregamento b√°sico de configura√ß√µes como fallback."""
    config_file = Path(config_path)
    
    if not config_file.exists():
        logger.error(f"[CONFIG] Arquivo n√£o encontrado: {config_path}")
        sys.exit(1)
    
    try:
        config = configparser.ConfigParser()
        config.read(config_path, encoding='utf-8')
        
        # Extrai configura√ß√µes essenciais
        configuracoes = {
            "resultado_dir": config.get("paths", "resultado_dir"),
            "app_key": config.get("omie_api", "app_key"),
            "app_secret": config.get("omie_api", "app_secret"),
            "calls_per_second": int(config.get("api_speed", "calls_per_second", fallback="4")),
            "start_date": config.get("query_params", "start_date"),
            "end_date": config.get("query_params", "end_date"),
        }
        
        logger.info("[CONFIG] Configura√ß√µes carregadas via fallback b√°sico")
        return configuracoes
        
    except Exception as e:
        logger.error(f"[CONFIG] Erro ao carregar configura√ß√µes: {e}")
        sys.exit(1)

# =============================================================================
# Pipeline Phases - Application Layer
# =============================================================================

class PipelineExecutor:
    """
    Executor do pipeline usando a nova arquitetura.
    
    Coordena a execu√ß√£o de todas as fases do pipeline usando
    os servi√ßos da application layer.
    """
    
    def __init__(self, service_locator: ServiceLocator):
        self.service_locator = service_locator
        self.config = service_locator.obter_configuracoes()
    
    def executar_pipeline_completo(self) -> None:
        """Executa pipeline completo usando nova estrutura."""
        try:
            logger.info("üöÄ INICIANDO PIPELINE REFATORADO - CLEAN ARCHITECTURE")
            logger.info("=" * 70)
            
            inicio_total = time.time()
            
            # Fase 1: Inicializa√ß√£o
            self._fase_inicializacao()
            
            # Fase 2: Extra√ß√£o de dados
            self._fase_extracao()
            
            # Fase 3: Verifica√ß√£o
            self._fase_verificacao()
            
            # Fase 4: Processamento
            self._fase_processamento()
            
            # Fase 5: Upload
            self._fase_upload()
            
            # Fase 6: Relat√≥rios
            self._fase_relatorios()
            
            # Finaliza√ß√£o
            fim_total = time.time()
            duracao_total = fim_total - inicio_total
            
            logger.info(" PIPELINE CONCLU√çDO COM SUCESSO!")
            logger.info(f"Tempo total: {formatar_tempo_total(duracao_total)}")
            logger.info("=" * 70)
            
        except Exception as e:
            logger.exception(f"‚ùå Erro cr√≠tico no pipeline: {e}")
            raise
    
    def _fase_inicializacao(self) -> None:
        """Fase 1: Inicializa√ß√£o do sistema."""
        logger.info("[FASE 1] üîß Inicializa√ß√£o e prepara√ß√£o")
        
        try:
            # Inicializar banco de dados
            iniciar_db("omie.db")
            
            # Atualizar datas de configura√ß√£o
            atualizar_datas_configuracao_ini()
            
            # Atualizar campos de registros pendentes
            atualizar_campos_registros_pendentes("omie.db", self.config['resultado_dir'])
            
            # Atualizar indexa√ß√£o temporal
            atualizar_anomesdia("omie.db")
            
            logger.info("[FASE 1] ‚úÖ Inicializa√ß√£o conclu√≠da")
            
        except Exception as e:
            logger.exception(f"[FASE 1] ‚ùå Erro na inicializa√ß√£o: {e}")
            raise
    
    def _fase_extracao(self) -> None:
        """Fase 2: Extra√ß√£o de dados da API."""
        logger.info("[FASE 2] üì• Extra√ß√£o de dados")
        
        try:
            omie_client = self.service_locator.obter_servico('omie_client')
            
            # Executar extra√ß√£o usando application services
            # Nota: Aqui seria implementada a chamada ass√≠ncrona
            logger.info("[FASE 2] Executando extra√ß√£o de dados...")
            
            # TODO: Implementar execu√ß√£o ass√≠ncrona do extrator
            # await baixar_xmls(omie_client, "omie.db")
            
            logger.info("[FASE 2] ‚úÖ Extra√ß√£o conclu√≠da")
            
        except Exception as e:
            logger.exception(f"[FASE 2] ‚ùå Erro na extra√ß√£o: {e}")
            # N√£o interrompe pipeline - continua com dados existentes
    
    def _fase_verificacao(self) -> None:
        """Fase 3: Verifica√ß√£o de integridade."""
        logger.info("[FASE 3]  Verifica√ß√£o de integridade")
        
        try:
            verificar_xmls()
            logger.info("[FASE 3] ‚úÖ Verifica√ß√£o conclu√≠da")
            
        except Exception as e:
            logger.exception(f"[FASE 3] ‚ùå Erro na verifica√ß√£o: {e}")
            # Continua pipeline mesmo com erros de verifica√ß√£o
    
    def _fase_processamento(self) -> None:
        """Fase 4: Processamento e compacta√ß√£o."""
        logger.info("[FASE 4] üì¶ Processamento e compacta√ß√£o")
        
        try:
            # Atualizar caminhos
            atualizar_caminhos_no_banco()
            
            # Compactar resultados
            compactar_resultados()
            
            logger.info("[FASE 4] ‚úÖ Processamento conclu√≠do")
            
        except Exception as e:
            logger.exception(f"[FASE 4] ‚ùå Erro no processamento: {e}")
            # Continua para upload mesmo com erro de compacta√ß√£o
    
    def _fase_upload(self) -> None:
        """Fase 5: Upload para OneDrive."""
        logger.info("[FASE 5]Upload para OneDrive")
        
        try:
            resultado_dir = Path(self.config['resultado_dir'])
            arquivos_zip = list(resultado_dir.rglob("*.zip"))
            
            if arquivos_zip:
                fazer_upload_lote(arquivos_zip, "XML_Compactados")
                logger.info(f"[FASE 5] ‚úÖ Upload de {len(arquivos_zip)} arquivos conclu√≠do")
            else:
                logger.info("[FASE 5] ‚ÑπÔ∏è Nenhum arquivo para upload")
                
        except Exception as e:
            logger.exception(f"[FASE 5] ‚ùå Erro no upload: {e}")
            # Continua para relat√≥rios mesmo com erro de upload
    
    def _fase_relatorios(self) -> None:
        """Fase 6: Gera√ß√£o de relat√≥rios."""
        logger.info("[FASE 6] üìã Gera√ß√£o de relat√≥rios")
        
        try:
            gerar_relatorio_vazios(self.config['resultado_dir'])
            logger.info("[FASE 6] ‚úÖ Relat√≥rios gerados")
            
        except Exception as e:
            logger.exception(f"[FASE 6] ‚ùå Erro na gera√ß√£o de relat√≥rios: {e}")
            # Erro em relat√≥rios n√£o √© cr√≠tico

# =============================================================================
# Fun√ß√£o principal refatorada
# =============================================================================

def main() -> None:
    """
    Fun√ß√£o principal refatorada usando Clean Architecture.
    
    Implementa:
    - Service Locator para dependency injection
    - Separa√ß√£o clara de responsabilidades
    - Estrutura modular e test√°vel
    - Tratamento robusto de erros
    """
    try:
        # Configurar logging
        configurar_sistema_logging()
        
        logger.info("üèóÔ∏è PIPELINE OMIE V3 - ARQUITETURA REFATORADA")
        logger.info("=" * 60)
        logger.info("üìã Estrutura: Clean Architecture + DDD")
        logger.info("üîß Padr√µes: Service Locator, Dependency Injection")
        logger.info("=" * 60)
        
        # Carregar configura√ß√µes
        config = carregar_configuracoes()
        
        # Configurar service locator
        service_locator.configurar_servicos(config)
        
        # Criar e executar pipeline
        executor = PipelineExecutor(service_locator)
        executor.executar_pipeline_completo()
        
        logger.info(" EXECU√á√ÉO CONCLU√çDA COM SUCESSO!")
        
    except KeyboardInterrupt:
        logger.warning("‚ö†Ô∏è Execu√ß√£o interrompida pelo usu√°rio")
        sys.exit(1)
    except SystemExit:
        raise
    except Exception as e:
        logger.exception(f"‚ùå Erro cr√≠tico no main: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()
'''

def main():
    """Fun√ß√£o principal do atualizador."""
    try:
        atualizador = AtualizadorMain()
        atualizador.executar_atualizacao()
        
        print("\n" + "="*60)
        print(" MAIN.PY ATUALIZADO COM SUCESSO!")
        print("="*60)
        print("üìã Mudan√ßas implementadas:")
        print("  ‚Ä¢ Imports atualizados para nova estrutura")
        print("  ‚Ä¢ Service Locator implementado")
        print("  ‚Ä¢ Dependency Injection b√°sico")
        print("  ‚Ä¢ Estrutura preparada para testes")
        print(f"\nüíæ Backup criado: {atualizador.backup_file}")
        print("\nüöÄ Pr√≥ximos passos:")
        print("1. Testar execu√ß√£o do novo main.py")
        print("2. Implementar testes unit√°rios")
        print("3. Adicionar mais dependency injection conforme necess√°rio")
        
    except Exception as e:
        logger.exception(f"‚ùå Erro durante atualiza√ß√£o: {e}")
        return 1
    
    return 0

if __name__ == "__main__":
    exit(main())
